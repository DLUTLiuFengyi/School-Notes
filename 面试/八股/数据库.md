---
typora-root-url: ..\pic
---

### 分布式

#### CAP

* 一致性：所有数据节点数据一致（相比于ACID的C，只关注于一个事务内的数据约束），所有节点访问同一份最新数据副本。

* 可用性：每个操作都能在一定时间内返回结果（成功或失败）

* 分区容忍性：partition tolerance 分布式系统出现网络分区时，仍能够对外提供服务。
* 最终一致性：系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS。

P一定要满足，在此基础上只能满足A或者C

一致性+容忍性：zk（任何时刻对zk的读请求都能得到一致性的结果，但zk不保证每次请求的可用性如在leader选择或半数以上机器不可用时服务就是不可用的），hbase

可用性+容忍性：cassandra，eureka

##### 事例

社交发帖：没有强一致性要求，用redis的AP模型即可

交易类型：强一致性要求，需要CP模型

服务注册：对同一个服务，即使注册中心不同节点保持的服务注册信息不同，也不会造成灾难性后果，因为对消费者来说，能消费才是最重要的，就算拿到的数据不是最新的，消费者本身也能尝试失败重试。选择AP模型

#### BASE

* basically available 基本可用

  响应时间可变慢、部分功能可不可用

* soft-state 软状态

  可存在中间状态（数据不一致），且其不影响整体可用性，即副本在同步间存在延时

* eventually consistent 最终一致性

对CAP中C与A权衡的结果，大大降低对系统的要求。

##### 核心思想

牺牲一致性来满足高可用性。部分数据不可用或不一致时，仍需保持整体可用。

##### 实现最终一致性

1. 读时修复：读数据时检查数据的不一致并进行修复
2. 写时修复：写数据时...
3. 异步修复：通过定时对账检查副本数据的一致性并修复

#### 分布式锁

* 基于DB实现
* 基于redis实现
* 基于zk实现

##### 基于redis实现分布式锁

redis单线程串行处理天然就是解决串行化问题，很适合用来解决分布式锁问题

可以选择 redis集群 或 哨兵模式，实现主从故障转移。当master节点出现故障，哨兵会从slave选取节点，变成新的master。

哨兵模式故障转移是由哨兵集群进行监控判断，当master出现异常（复制中止）时，推选新的slave成为master。哨兵在重新进行选举并不在意主从数据是否复制完毕具备一致性，**所以redis的复制模式属于AP模式**：在主从复制中“主”有数据，但“从”还没有数据，此时一旦master宕机或者网络抖动等，可能切换到从节点，此时可能导致两个业务线程同时获得两把锁。

1. 线程1向主节点请求锁
2. 线程1获取锁
3. 线程1开始执行业务
4. 此时主从之间还未同步这把新生成的锁
5. 主节点宕机
6. 从节点变成新主节点
7. 线程2向新主请求锁
8. 线程2获得锁
9. 线程2开始执行业务
10. 此时1和2同时执行任务

上述问题不是redis的缺陷，只是因为其采用了AP模型。官方推荐redlock算法解决，其至少需要3个redis主从实例来实现。

#### 分布式事务

都遵循BASE，都是最终一致性模型

* 两阶段提交

  原始

* 补偿事务

* 本地消息表

  业界使用最多

* MQ事务消息

##### 两阶段提交

1.请求阶段（commit-request phase，或称表决阶段，voting phase）
在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。
在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。

2.提交阶段（commit phase）
在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。
当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。
参与者在接收到协调者发来的消息后将执行响应的操作。

总结：1. 协调者要求每个参与者**预提交**此操作，并反映是否可以提交 2. 协调者要求每个DB提交数据，或者回滚数据

缺点：同步阻塞问题，不满足高并发。网络问题也会造成通知仅被一部分参与者收到并执行commit操作，其他参与者一直处于阻塞态。

三阶段提交

在协调者与参与者中都引入超时机制

##### 本地消息表

核心思想是将分布式事务拆分成本地事务进行处理。（大事务拆成小事务）

1. 创建订单时，新增一个本地消息表，把创建订单和扣减库存写入本地消息表，放在同一个事务
2. 配置一个定时任务去轮询这个本地事务表，扫描该表，把没用发出的消息发送给库存服务，库存服务收到消息后，进行减库存操作，并写入库存服务器的事务表，更新事务表
3. 库存服务器通过定时任务或直接通知订单服务，订单服务在本地消息表更新状态

对一些扫描发送未成功的任务，进行重新发送。

本地消息表是BASE理论，最终一致性模式。

#### 高并发

#### 容灾

### MySQL

#### ACID

* 原子性：undo log实现

* 一致性：由另外三性综合保证

  执行事务前后，数据保持一致。无论事务是否成功，转账者和收款者总额应该是不变的。

* 隔离性：加锁

* 持久性：redo log实现

  一个事务被提交后，对DB的改变是持久的，即使DB发生故障也不应该有任何影响

#### 如何保证数据库数据的一致性

#### 经典问题

1. 脏读：一个事务对DB的修改还没提交，另一个事务使用到了这个未提交的数据，被读到的叫“脏数据”
2. 不可重复读：一个事务多次读同一个数据，此时另一个事务对该数据进行修改，导致前者两次读到的数据是不同的
3. 幻读：与2类似，一个事务读取了几行数据，此时另一个事务插入了一些数据，导致前者在随后查询中读到原本不重复的记录

#### 事务隔离级别

1. 读未提交：最低级别，允许读取尚未提交的数据变更，可能导致脏读、不可重复读、幻读
2. 读已提交：可能导致不可重复读、幻读
3. 可重复读：对同一字段的多次读取结果都是一致的，可能导致幻读
4. 可串行化：完全服从ACID，所有事务依次逐个进行

mysql innoDB默认支持可重复读。innoDB允许使用next-key lock算法（通过应用加锁读）来避免幻读产生

#### 为什么用B+树

索引的演化：

* 哈希索引：复杂度o(1)，哈希值会碰撞，不支持排序

  链地址法解决碰撞

  数据检索常出现范围查找，哈希索引不适合

* 二叉查找树：复杂度o(logn)

  可以解决范围查找（查右或左子树）

  极端情况会退化成线性链表，二分查找也会退化为遍历查找o(n)，树很深，常出现在主键id自增

* AVL树和红黑树

  红黑树不存在极端的o(n)情况，但其实红黑树并没有完全解决二分查找树“右倾”趋势（虽然没有退化为线性链表那么极端）

  AVL树查找性能比红黑树强，但**数据库查询数据瓶颈在磁盘IO**，一个节点只能存一个索引，一次磁盘IO只能取出一个节点上的数据加载到内存中，且深度大

  磁盘 IO 有个特定：**从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的**

  因此B树优化思路：尽可能在一次磁盘 IO 中多读一点数据到内存

* B树：查找性能o(h*logn)，深度比二叉树浅，查找速度更快，且支持范围查找

* B+树：叶子节点才存数据（MyISAM存地址 InnoDB存具体数据），查找性能比B树稳定，叶子节点用链表形式连起来，对顺序查找支持友好，且不会有返回查找操作。

  高度降低，减少了磁盘IO

#### B树与B+树区别

* B树一个节点中存数据，B+树存索引（地址），因此B树一个节点存不了很多数据但B+树一个节点能存很多索引（不包括叶子节点）
* B+树叶子节点用了一个链表串联起来，便于范围查找

#### Server层

* 连接
  * 先检查sql语句是否有权限
* （缓存）
* 分析
  * 词法：提取关键字，查询表名，字段名，查询条件
  * 语法：sql是否符合mysql语法
* 优化
  * 索引选择，关联顺序
* 执行
  * 调用引擎接口，返回结果

通用日志模块binlog（InnoDB日志是redo log）

#### 三种log

![](D:\ideaprojects\School-Notes\面试\pic\db3.png)

##### redo log

确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

DB内核引擎提供

##### bin log

server端提供。必须与redo log内容一致

先写redo log再写undo log

##### undo log

undo日志用于记录事务开始前的状态，用于事务失败时的回滚操作

#### 存储引擎层

数据的存储和读取，InnoDB

#### SQL执行

select：权限 分析 优化 权限 执行器 引擎

update：权限 分析 权限 执行器 引擎-redo-log(prepare状态)  binlog  redo-log(commit状态)

​				调用api写数据 InnoDB把数据保存在内存 记录redo-log redo-log进入prepare状态 告诉执行器执行完成 执行器收到并记录binlog 调用引擎接口 提交redo-log为提交状态

redo log两阶段提交：写完binlog后再提交redo log，是为了保证数据一致性

#### 查找很慢怎么办

思想：避免全表扫描，注意索引（注意where子句查询条件满足最左前缀原则），允许脏读

核心思想是：用一个或多个查询条件(查询条件要求至少输入一个)得到临时表，每个查询条件如果查到集合，就更新这张临时表，最后汇总的时候，只需判断这个临时表是否有值。以此类推，可以建立多个临时表，将查询条件汇总。

* 分析原SQL语句
* 优化设计
  * 用临时表扫描替代全表扫描
  * 用exists和not exists替代in或not in
  * 尽量不用模糊查询like
  * 建立适当索引
  * 避免*号

#### 各种锁

* 行锁：只有A事务commit后，B事务才可以对相同行进行更新（读），否则B会阻塞（读到A之前的值）
* 表锁：索引失效（or关键字）会让行级锁变成表锁，需要等事务Acommit之后
* 间隙锁：发生在范围查询中，要查主键id是1-9之间的数据，假如原有id 1 3 5 7 9，则现在是无法插如2 4 6之类的数据进去的

#### MVCC 多版本并发控制

为了提升并发性能，通过行级锁的变种，避免很多情况下的加锁的操作

适用于读已提交和可重复读

多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是**为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照**。

```bash
而MVCC其实是基于ReadView以及undo log多版本链条实现。
```

如果一直有事务进行数据的修改，那么就会形成一条由回滚指针串联的undo log多版本链条。

还需要一种机制可以利用undo log多版本链来实现事务隔离。这个机制就是ReadView。

执行事务的时候，会生成一个ReadView

https://www.jianshu.com/p/abc940938e29

![](/mvcc1.jpg)

执行过程如下：

1. 如果被访问版本的trx_id=creator_id，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问
2. 如果被访问版本的trx_id<min_trx_id，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问
3. 被访问版本的trx_id>=max_trx_id，表明生成该版本的事务在当前事务生成ReadView后才开启，该版本不可以被当前事务访问
4. 被访问版本的trx_id是否在m_ids列表中
   4.1 是，创建ReadView时，该版本还是活跃的，该版本不可以被访问。顺着版本链找下一个版本的数据，继续执行上面的步骤判断可见性，如果最后一个版本还不可见，意味着记录对当前事务完全不可见
   4.2 否，创建ReadView时，生成该版本的事务已经被提交，该版本可以被访问

核心：判断要被访问版本的trx_id是不是在min到max这个范围中，在的话判断还在不在目前活动的m_id列表中。通过undo链向上回溯版本。

RC以及RR的区别就在于，RC事务隔离级别下，每次获取数据的时候，都会重新生成新的ReadView，再根据ReadView中的信息进行数据读取的判断。

#### 慢查询日志

### 索引

为什么快？因为让无序数据变成有序（相对）

没有用索引的话需要遍历双向链表（叶子层）来定位对应的页，现在通过 **“目录”** 就可以很快地定位到对应的页上了！（从根节点从上往下，二分查找，时间复杂度近似为O(logn)）。其实底层结构就是B+树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录。

* 经常需要搜索的列上
* 经常使用在where子句的列上
* 经常要排序的列上，利用索引的排序加快排序查询时间
* 中到大型表（特大型不合适，维护成本高）
* 经常连接的列上（主要是外键）
* 避免where子句中施加函数（会造成无法命中索引）

#### 数据结构

哈希索引：哈希表，查询性能最快

BTree索引：大部分场景

#### 引擎实现

MyISAM

B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。

InnoDB

其数据文件本身就是索引文件。相比MyISAM（索引文件和数据文件是分离的），其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

![](D:\ideaprojects\School-Notes\面试\pic\db1.png)

![](D:\ideaprojects\School-Notes\面试\pic\db2.png)

#### 注意

1. 单行访问是很慢的。特别是在机械硬盘存储中(SSD的随机I/O要快很多，不过这一点仍然成立）。如果服务器从存储中读取一个数据块只是为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引，用以提升效率。
2. 按顺序访问范围数据是很快的，这有两个原因。第一，顺序 I/O 不需要多次磁盘寻道，所以比随机I/O要快很多（特别是对机械硬盘）。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUPBY查询也无须再做排序和将行按组进行聚合计算了。
3. 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么存储引擎就 不需要再回表查找行。这避免了大量的单行访问，而上面的第1点已经写明单行访问是很慢的。

#### InnoDB与MyISAM

* 前支持事务，后不支持

* 前支持外键，后不支持

* 前是聚集索引，后是非聚集索引

  聚集索引：数据存储与索引放在一块，索引结构的叶子节点保存了行数据。

  非聚簇索引：数据与索引分开存储，表数据存储顺序与索引顺序无关

  * InnoDB主索引B+树存的是主键id，叶子节点存的是数据

    当为某个字段user_name添加索引时， InnoDB 就会建立 user_name 索引 B+树，节点里存的是 user_name 这个 KEY，叶子节点存储的是**主键 KEY**。拿到主键 KEY 后，InnoDB 才会去主键索引树里根据刚在 user_name 索引树找到的主键 KEY 查找到对应的数据。因此查找过程是先 辅助索引树 再 主键索引树。

  * MyISAM的数据和索引落在两个不同的文件中，主索引B+树存的是主键id，叶子节点存的是对应数据的物理地址

    当为某个字段添加索引时，同样会生成对应字段的索引树，该字段的索引树的叶子节点同样是记录了对应数据的物理地址，然后也是拿着这个物理地址去数据文件里定位到具体的数据记录。

* 前最小锁粒度是行级锁，后是表锁，导致一个更新语句会让其他查询和更新都阻塞，并发受限

* 如果只通过主键索引查数据，那InnoDB比MyISAM快，如果有辅助索引的场景，那比MyISAM慢

* 绝大多数只有读，则用MyISAM（查找性能更好），读写频繁用InnoDB

因为 InnoDB 需要节省存储空间。一个表里可能有很多个索引，InnoDB 都会给每个加了索引的字段生成索引树，如果每个字段的索引树都存储了具体数据，那么这个表的索引数据文件就变得非常巨大（数据极度冗余）。

InnoDB中在聚簇索引之上建立的索引称为辅助索引，像复合索引、前缀索引、唯一索引

聚簇索引默认是主键，若表中没有主键，则InnoDB...（唯一非空索引->内部生成隐式主键）

#### 最左前缀原则

如果查询的时候查询条件精确匹配索引的左边连续一列或几列（一定要从最左边那个开始），则此列就可以被用到（跟覆盖索引有所区别）。

如果建立的是复合索引，索引的顺序要按照建立时的顺序，即从左到右。

因为先给a列排序，再给b列排序，b只在a相同的情况下才有序

#### 索引实战

```mysql
select sql_no_cache * from user where phone='1365' and lan_id=121 and regoin_id=53;
alter table user add index idx_phone_lan_region(phone, lan_id, region_id);
```

加减乘除 != <> is null is not null or  函数如sum(), round()等会使索引失效
