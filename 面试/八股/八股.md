---
typora-root-url: pic
---

### Spring

#### Spring IoC

控制反转：对象的控制权交由程序管理而不是程序员

##### 如何实现

依赖注入：依赖关系由spring来解决。本来我接受各种参数来构造一个对象，现在只接受一个参数——已经实例化的对象。

spring通过xml配置读取要创建的对象的类名等属性信息，然后通过反射创建对象，放入bean容器中

#### Bean

Bean包括几个概念。

- 概念1：**Bean容器**，或称spring ioc容器，主要用来管理对象和依赖，以及依赖的注入。
- 概念2：bean是一个**Java对象**，根据bean规范编写出来的类，并由bean容器生成的对象就是一个bean。
- 概念3：bean规范。

#### 常见注解

@Autowired 自动导入对象到类中， Spring 容器帮我们自动装配 bean

@GetMapping("users")` 等价于`@RequestMapping(value="/users",method=RequestMethod.GET)

@PostMapping("users")` 等价于`@RequestMapping(value="/users",method=RequestMethod.POST)

`@SpringBootApplication`就是几个重要的注解的组合，为什么要有它？当然是为了省事，避免了我们每次开发 Spring Boot 项目都要写一些必备的注解。

```java
@RestController
@RequestMapping("test")
public class HelloWorldController {
    @GetMapping("hello")
    public String sayHello() {
        return "Hello World";
    }
}

//浏览器 http://localhost:8333/test/hello 可以在页面正确得到 "Hello World" 
```

#### Spring AOP

AOP：面向切面编程

切面：横切面，与纵切面（面向对象中如何更详细地描述一个对象）相对，是众多类都会使用到的与业务无关的常规操作（日志、安全认证、事务等）

#### Restful风格

#### Spring中的设计模式

- **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。

- **代理设计模式** : Spring AOP 功能的实现。

- **单例设计模式** : Spring 中的 Bean 默认都是单例的。

  保证一个类只有一个实例，并提供一个访问它的全局访问点（构造方法是private的，外部不能调用）

- **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。

- **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。

- **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。

- **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。

单例模式补充：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。

### Spring Boot

### Spring MVC

#### 结构

model处理数据逻辑的部分，通常负责在数据库中存取数据。

view处理数据显示的部分。通常是依据数据模型创建的。

controller处理数据交互的部分。通常负责从视图读取数据，控制用户输入，并向模型发送。

* 用户发请求
* 控制器接收请求，调用业务类，派发页面
* 交给模型层处理：model service dao entity
* 模型层返回一个结果给控制器
* 控制器视图渲染 view
* 控制器响应给用户

#### 流程说明（重要）

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）

#### 优缺点

封装（分层）的思想，来降低耦合度，从而使我们的系统更灵活，扩展性更好。

优点

* 多个视图共享一个模型，大大提高代码的可重用性。
* 三个模块相互独立，改变其中一个不会影响其他两，所以具有良好的松耦合性。
* 控制器可以用来连接不同的模型和视图去完成用户的需求，灵活。

缺点

* 增加结构复杂度

* 视图其实与控制器会过于紧密

  视图没有控制器的存在，其应用是很有限的

* 视图对模型数据的访问低效

  依据模型操作接口的不同，视图可能需要多次调用才能获得足够的显示数据。对未变化数据的不必要的频繁访问，也将损害操作性能。

### 设计模式

#### 代理模式

在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。

### Redis

### 高并发 高性能 高可用

#### 系统拆分

一个拆成多个，每个连接一个DB，这样就多个DB了

#### 缓存

必须。大部分高并发都是读多写少，完全可以在DB和缓存都写一份，读的时候走缓存。

redis单机几万并发。

#### 消息队列

必须。因为还是会出现高并发写。

大量的写请求灌入MQ，排队慢慢玩（排队等待），后边系统消费后慢慢写。

可以考虑异步写提高并发性。

#### 分库分表

DB层面。一个库拆成多个库来抗高并发，一个表拆成多个表提高跑sql性能。

#### 读写分离

大部分DB都是读多写少，没必要所有请求都集中在一个库上。搞个主从架构，主库写入从库读取。

#### ES

### Kafka

kafka其实有三个功能：消息队列，持久式存储，流式处理

#### 优势

大量使用批量处理和异步思想，最高每秒千万级

基于scala和java编写，大数据和流式处理生态兼容良好

#### 模型

##### 队列模型

队列作为消息通信载体，生产-消费者模式

缺点是不适用于：将生产者产生的消息分发给多个消费者且每个消费者都能接收到完整的消息内容

##### 发布-订阅模型

为了解决队列模型的问题

使用topic作为消息通信载体，类似广播，发布者发布一条消息，该消息通过topic传递给所有订阅者

队列模型是此模型的特例（只有一个订阅者）

#### 概念

producer生产者，consumer消费者，broker代理：独立的kafka实例，多个kafka broker组成一个kafka集群

partition分区：属于topic的一部分，一个topic有多个partition，同一topic下的partition可以分布在不同的broker，实际对应于消息队列里的队列

#### 多副本机制

为分区引入多副本机制，多副本间有leader，其他副本称为follower，我们发送的消息会被发送到leader，然后follower才能从leader中拉取消息进行同步

##### 好处

* 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）
* Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力

#### zookeeper

主要为kafka提供元数据管理

* broker注册：有一个专门**用来进行 Broker 服务器列表记录**的节点，每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去

* topic注册：同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护

* 负载均衡： 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

#### 如何保证消息消费顺序

每次添加消息到 Partition的时候都会采用尾加法

Kafka 只保证 Partition中的消息有序，而不能保证 Topic中的 Partition 的有序。

因此，如何保证 Kafka 中消息消费的顺序有下面两种方法：

1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition。

消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

#### 如何保证消息不丢失

##### 生产者丢失消息

检查失败原因，重新发送，可以设置重试次数、重试间隔

##### 消费者丢失消息

消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

**手动关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。** 但是，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。

##### kafka丢失消息



### 3种缓存读写策略

热点数据可以提前放入cache中

#### 旁路缓存

适合读请求较多

服务端同时维护DB和cache，以DB结果为准

写：先更新DB，然后直接删除cache

读：从cache中读数据，读到就直接返回；读不到，从DB中读然后返回；服务器再把从DB获取到的数据放到cache中

##### 为什么不能先删除cache再更新DB？

因为为造成DB和cache数据不一致，比如请求1先写A，请求2随后读A的话会产生数据不一致（请求1先把cache中A删除，请求2从DB中读数据，请求1才把DB中的A更新成自己想更新的值）

那原理的先更新DB后删除cache的方法就没问题吗？

理论上还是会有不一致问题，但概率很小，因为cache写入的速度比DB写入的数据快很多

##### 缺点

* 首次请求数据一定不在cache

  解决：可先把热点数据提前放进cache

* 写较频繁的话cache中的数据会频繁被删除，会影响命中率

  解决1：强一致性场景的话，更新DB同时更新cache，加一个锁保证更新cache时线程安全

  解决2：短暂允许不一致场景的话，更新DB同时更新cache，但给cache加一个较短时间间隔，可保证即使数据不一致影响也较小

#### 读写穿透

服务端把cache视为主要数据存储，从中读取数据并将数据写入其中

cache负责将此数据读取和写入DB，减轻app(server?)职责

少用，因为cache写入DB功能少

写：先查cache，cache不在，直接更新DB；cache中存在，先更新cache，然后cache自己更新DB（同步更新）

读：从cache中读数据，读到就直接返回；读不到，cache自己从DB加载数据，然后返回

#### 异步缓存写入

也是由cache自己负责cache和DB的读写

Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新cache，不直接更新 DB，而是改为**异步批量**的方式来更新 DB。

消息队列中消息异步写入磁盘，InnoDB buffer pool机制

使用数据经常变化且对一致性要求不高，如浏览量、点赞量

### 实战

#### 服务限流

#### 100亿个数topk

### Mybatis

MyBatis 是一个支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以**使用简单的 XML 或注解来配置和映射原生信息，将接口和普通Java对象映射成数据库中的记录**。

Mybatis的运行分为两个部分，第一部分是读取配置文件缓存到Configuration对象，用以创建SqlSessionFactory，第二部分是SqlSession的执行过程。

流程
1、使用XML配置文件或Java代码方式生产SqlSessionFactory

2、使用Resources类的getResourceAsStream()方法读取XML配置文件

3、使用SqlSessionFactoryBuilder类的build()方法创建sqlSessionFactory

4、得到sqlSessionFactory类后使用该类的openSession()获取SqlSession

5、得到SqlSession后需要实现映射器的功能，映射器有一个接口和该接口对应的XML映射文件或使用注解组成

6、使用SqlSession的getMapper()方法得到具体的接口类对象

步骤
1、创建MyBatis配置文件：mybatis-config.xml（不使用Java代码方式）（1）配置数据库环境（2）配置映射器的XML映射文件2、创建一个生成SqlSession的sqlSessionFactory类：SqlSessionFactoryUtils。对应流程的2、3、4

3、定义一个接口和该接口对应的XML映射文件：XxxMapper、XxxMapper.xml（不使用注解方式）

4、使用SqlSession的getMapper()方法得到具体的接口类对象

5、执行完业务后记得关闭sqlSession

#### 如何对jdbc封装

SqlSession接口通过DefualtSqlSession实例调用Executor接口实现对sql语句的处理和封装

* MyBatis核心配置文件：配置数据源、事务管理方式、指定sql映射文件位置
* SqlSessionFactory：根据核心配置文件生产的工厂对象，作用是创建SqlSession
* SqlSession：提供开发人员的一个接口，作用是操作数据库增删改查
* Executor：一个在SqlSession内部使用的接口，作用是负责对数据库的具体操作
* mapped statement：底层封装工具，作用是生成具体的sql命令以及对查询结果集二次封装

#### dirty属性

SqlSession的成员属性，变成true时表示即将改DB的数据，代表数据库数据与内存中数据不一致了，需要更新
