---
typora-root-url: pic
---

### Spark

#### Driver和Executor

它们是计算相关组件

Driver

* 定义：是main函数入口，作业的主进程，拥有SparkContext实例
* 功能：负责向集群申请资源，向master注册信息，作业的调度、解析，生成stage并调度Task到Executor，包括DAGScheduler，TaskScheduler。分发代码到worker节点

Executor有2个核心功能

* 运行组成spark应用的任务，并将结果返回给驱动器进程

* 通过自身的Block Manager为用户程序中要求缓存的RDD提供 **内存式存储** 

  RDD是直接缓存在exeutor进程中的，因此任务可以在运行时充分利用缓存数据加速运算

Executor是集群运行在工作节点（worker）中的一个jvm进程，是集群中专门计算的节点，主要执行task

#### Master和Worker

它们是资源相关组件

只在standalone模式存在这两个概念，因为需要spark自己提供资源管理和资源调度。

类似对比于yarn中的ResourceManager和NodeManager

master：一个进程，主要负责资源调度和分配，并进行集群的监控等

worker：也是进程，一个worker运行在集群中的一台主机上，由master分配资源对数据进行并行处理和计算

worker是包工头，负责管理其节点上的executor

如果资源管理交给yarn来做，yarn中的resourceManager相当于master，NodeManager相当于worker

#### Standalone

1）特点：

（1）master/slave架构，集群由Master与Worker节点组成，程序通过与Master节点交互申请资源，Worker节点启动Executor运行；

（2）standalone调度模式使用FIFO调度方式；

（3）无依赖任何其他资源管理系统，Master负责管理集群资源

2）优点：

（1）部署简单；

（2）不依赖其他资源管理系统。

3）缺点：

（1）默认每个应用程序会独占所有可用节点的资源，当然可以通过spark.cores.max来决定一个应用可以申请的CPU cores个数；

（2）可能有单点故障，需要自己配置master HA

#### 容错机制原理

即Lineage机制原理

Lineage（又称为RDD运算图或RDD依赖关系图）是在RDD上执行transformations函数并创建logical execution plan（逻辑执行计划）的结果，是RDD的逻辑执行计划，记录了RDD之间的依赖关系。

使用Lineage实现spark的容错，本质上类似于数据库中重做日志。

#### Executor full gc

可能导致Executor僵死问题，海量数据的shuffle和数据倾斜等都可能导致full gc。

以shuffle为例：

* 伴随着大量的Shuffle写操作，JVM的新生代不断GC
* Eden Space写满了就往Survivor Space写，同时超过一定大小的数据会直接写到老生代，当新生代写满了之后，也会把老的数据搞到老生代
* 如果老生代空间不足了，就触发FULL GC
* 还是空间不够，那就OOM错误了，此时线程被Blocked，导致整个Executor处理数据的进程被卡住。

#### ApplicationMaster

如果计算和资源（Driver和Master）直接进行交互，则会增加耦合度

因此让D和M并不能直接交互

在二者间放一个ApplicationMaster

Driver委托AM，AM再向Master申请资源

#### Tips

* 程序在运行前，已经申请过资源了，driver和executor通信，不需要和master进行通信

* 一个app对应一个context，app存在多个job，一个action触发一个job
* task的调度线程和Executor资源申请是异步的，因此会出现Application在没有获得足够的资源，job就开始执行了的情况

#### Task

task分为resultTask和shuffleMapTask

#### Shuffle

需要shuffle：某种具有共同特征的数据汇聚到一个计算节点进行计算

#### BlockManger

每个数据分片都对应具体物理位置，数据的位置是被BlockManager管理

#### 数据本地性

读取在本地节点缓存、本地节点硬盘、非本地节点的数据

尽量使用cache

cache是lazy的，所以必须通过一个action的触发，才能真正将RDD cache到内存中

#### RDD操作类型

* transformation

* action，触发SparkContext提交job，并将数据输出spark系统

* controller，controller是控制算子，需要action触发，主要是对数据进行缓存，对性能和效率的有很好的支持

  cache，persist，checkpoint，都可以将RDD持久化

  持久化作用：

  * 计算链条非常长，重新恢复要算很多步骤，则用persist
  * checkpoint所在的rdd要持久化persist
  * shuffle之后为什么要persist，shuffle要进行网络传输，风险很大，数据丢失重来，恢复代价很大
  * shuffle之前进行persist，框架默认将数据持久化到磁盘，这个是框架自动做的

#### join操作优化

将多份数据进行关联是数据处理过程中非常普遍的用法，不过在分布式计算系统中，这个问题往往会变的非常麻烦，因为框架提供的 join 操作一般会将所有数据根据 key 发送到所有的 reduce 分区中去，也就是 shuffle 的过程。造成**大量的网络以及磁盘IO消耗**，运行效率极其低下，这个过程一般被称为 reduce-side-join。

如果其中有张表较小的话，我们则可以自己实现在 map 端实现数据关联，跳过大量数据进行 shuffle 的过程，运行时间得到大量缩短，根据不同数据可能会有几倍到数十倍的性能提升。当大表和小表join时，用map-side join能显著提高效率。

#### 参数广播

多进程编程中，进程之间可以创建共享内存，这是最快的进程通信的方式。那么，对于分布式系统，如何共享数据呢？Spark提供了两种在Spark集群中创建和使用共享变量的机制：**广播变量**和**累加器**。

Spark会自动广播每个stage任务需要的通用数据。这些被广播的数据以序列化的形式缓存起来，然后在任务运行前进行反序列化。

应用场景：当任务跨多个stage，且需要同样的数据时，或以反序列化的形式来缓存数据时。

广播变量会在每个worker节点上保留一份副本，而不是为每个Task保留一份副本。

广播变量是task共享级别，累加器（全局唯一只增不减记录全局集群的唯一状态）是executor共享级别

#### 序列化

缓存数据时可以选择是否同时进行序列化。序列化后占用的空间会减少，但有序列化/反序列化的成本，很耗cpu。
如果确定需要使用序列化，则应设置序列化的方式，默认是java自带的序列化机制，也可以通过kyro等框架优化序列化效率。

即使完全无其它属性，一个java对象都要占据8B的内存，包括：锁标志位、经历了几次gc、类的类信息等，因此序列化可节省此部分的空间。

##### 如何处理不能被序列化的数据

将不能被序列化的对象封装成object

#### collect

**driver**通过collect把集群中**各个节点**的内容收集过来**汇总**成结果。

collect返回结果是Array类型的，collect把各个节点上的数据抓过来，抓过来数据是Array型，collect对Array抓过来的结果进行合并，合并后Array中只有一个元素，是tuple类型（KV类型的）的。

#### 工作机制

* 用户在client端提交作业后，会由driver运行main方法并创建spark context上下文
* sparkcontext向资源管理器注册并申请运行executor资源
* 资源分配器分配executor资源，executor运行情况将随着心跳分发到资源管理器上
* driver（sparkcontext）读取rdd算子生成dag图，dagscheduler按照rdd之间的依赖关系划分stage，taskscheduler将每个stage划分为多个task，并将task set分发到各个worker的executor中执行，同时**sparkcontext将应用程序代码发送给executor**

#### Spark调优

检查并行度，检查持久化和shuffle争用的内存比例

##### spark.default.parallelism

1）参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能；

2）很多人都不会设置这个参数，会使得集群非常低效，你的cpu，内存再多，如果task始终为1，那也是浪费，spark官网建议task个数为CPU的核数*executor的个数的2~3倍。

##### spark.storage.memoryFraction

1）用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6,，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘；

2）如果持久化操作比较多，可以提高spark.storage.memoryFraction参数，使得更多的持久化数据保存在内存中，提高数据的读取性能，如果shuffle的操作比较多，有很多的数据读写操作到JVM中，那么应该调小一点，节约出更多的内存给JVM，避免过多的JVM gc发生。在web ui中观察如果发现gc时间很长，可以设置spark.storage.memoryFraction更小一点。

##### spark.shuffle.memoryFraction

1）shuffle从上一个task拉去数据过来，要在Executor进行聚合操作，聚合操作时使用Executor内存的比例由该参数决定，默认是20%如果聚合时数据超过了该大小，那么就会spill到磁盘，极大降低性能；

2）**如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上**，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。

#### 不需要排序的hash shuffle是否一定比需要排序的sort shuffle速度快

不一定，当数据规模小，Hash shuffle快于Sorted Shuffle数据规模大的时候；当数据量大，sorted Shuffle会比Hash shuffle快很多，因为数量大的有很多小文件，不均匀，甚至出现数据倾斜，消耗内存大

##### hash shuffle不足

1）shuffle产生海量的小文件在磁盘上，此时会产生大量耗时的、低效的IO操作；

2）容易导致内存不够用，由于内存需要保存海量的文件操作句柄和临时缓存信息，如果数据处理规模比较大的化，容易出现OOM；

3）容易出现数据倾斜，导致OOM。

##### 解决hash不足（在map端产生小文件）？

conslidate根据cpu个数决定每个task shuffle map端产生多少个文件，假设原来有10个task，100个reduce，每个CPU有10个CPU，那么使用hash shuffle会产生10* 100=1000个文件，conslidate产生10* 10=100个文件

##### sort shuffle不足

1）如果mapper中task的数量过大，依旧会产生很多小文件，此时在shuffle传递数据的过程中reducer段，reduce会需要同时大量的记录进行反序列化，导致大量的内存消耗和GC的巨大负担，造成系统缓慢甚至崩溃

2）如果需要在分片内也进行排序，此时需要进行mapper段和reducer段的两次排序

#### 数据本地性

具体的task运行在哪个机器上，由dag划分stage的时候确定的（不是task吗？）

#### spark调优

1. 平台层面：提高数据本地性，选择高效存储格式如parquet
2. 应用程序层面：filter优化来降低过多小任务，降低单条记录的资源开销，处理数据倾斜等
3. jvm层面：设置合适的资源量，设置合理的jvm，启用高效序列化方法如kyro，增大off heap内存

#### task快速启动

executor生命周期与app一样，即使没有job运行也存在，所以task可以快速启动

#### 为什么比mapreduce快

* 基于内存计算，减少低效磁盘交互
* 高效调度算法，基于DAG
* 容错机制 血缘关系 

#### 与maprecuce shuffle机制异同（版本过老）

1）从 high-level 的角度来看，两者并没有大的差别。 都是将 mapper的输出进行 partition，不同的 partition 送到不同的 reducer。Reducer 以内存作缓冲区，边 shuffle 边 aggregate 数据，等到数据 aggregate 好以后进行 reduce() 。

2）从 low-level 的角度来看，两者差别不小。 

* Hadoop MapReduce 是 sort-based，进入 combine() 和 reduce() 的 records 必须先 **sort**。这样的好处在于 combine/reduce() 可以处理大规模的数据，因为其输入数据可以通过外排得到（mapper 对每段数据先做排序，reducer 的 shuffle 对排好序的每段数据做归并）。
* Spark 默认选择的是 hash-based，通常使用 HashMap 来对 shuffle 来的数据进行 aggregate

3）从实现角度来看，两者也有不少差别。 

* Hadoop MapReduce 将处理流程划分出明显的几个阶段：map(), spill, merge, shuffle, sort, reduce() 等。每个阶段各司其职，可以按照过程式的编程思想来逐一实现每个阶段的功能。
* 在 Spark 中，没有这样功能明确的阶段，只有不同的 stage 和一系列的 transformation()，所以 spill, merge, aggregate 等操作需要蕴含在 transformation() 中。

#### RDD Resilient Distributed Dataset

弹性的，自动容错的，分区的，只读的记录集合

从物理的角度来看rdd存储的是block和node之间的映射

##### 数据结构

1个RDD对象，包含如下5个核心属性。

1）一个分区列表，每个分区里是RDD的部分数据（或称数据块）。

2）一个依赖列表，存储依赖的其他RDD。

3）一个名为compute的计算函数，用于计算RDD各分区的值。

4）分区器（可选），用于键/值类型的RDD，比如某个RDD是按散列来分区。

5）计算各分区时优先的位置列表（可选），比如从HDFS上的文件生成RDD时，RDD分区的位置优先选择数据所在的节点，这样可以避免数据移动带来的开销。

##### 弹性体现

1）自动进行内存和磁盘的存储切换；

2）基于Lineage的高效容错；

3）task如果失败会自动进行特定次数的**重试**；

4）stage如果失败会自动进行特定次数的重试，而且只会计算失败的分片；

5）checkpoint和persist，数据计算之后**持久化缓存**

6）数据调度弹性，DAG TASK调度和资源无关

7）数据分片的高度弹性，分片很多碎片可以合并成大的

#### Shuffle机制

##### 要点

* shuffle过程
* shuffle中间结果如何存
* shuffle数据如何拉取

##### 会进行shuffle的算子

reduceByKey，join，distinct，repartition

#### 解决数据倾斜

* 定位原因：OOM，还是任务执行缓慢。看web UI，看日志

* 解决：

  * 避免不必要shuffle

    * 广播小表
    * 将reduce-side-join提升为map-side-join

  * 分拆发生数据倾斜的记录，分成几个部分，然后合并join后的结果

  * 改变并行度

    原来可能是并行度小导致个别task数据压力大

  * 两阶段聚合：先局部聚合再全局聚合
  * 自定义partitioner，分散key的分布，使其更均匀

#### 集群规模

目前处于编写和测试阶段，3台机子，1个master2个slave，3台都是worker，每台64核、128G内存

#### DAGScheduler

##### stage划分算法说明

从触发action操作的rdd开始往前倒推，首先会为最后一个rdd创建一个stage,继续往前倒退的时候，如果发现对某个 rdd是宽依赖，那么就会将该宽依赖的rdd创建一个新的stage,之前面的那个rdd就是新的stage的最后一个rdd。然后以次类推，继续往前倒退，根据窄依赖和宽依赖进行stage的划分，知道所有的rdd全部遍历完成。

##### 划分stage的作用

在spark中提交的应用都会以**job**的形式进行执行，job提交后会被划分为多个**stage**,然后把stage封装为**TaskSet**提交到**TaskScheduler**到executor中执行。

#### 与mapreduce区别

* hadoop一个app是一个job，spark一个app有多个job

  hadoop的多个job需要自己管理关系

* hadoop在mr过程中会重复读写hdfs，造成大量io

* spark的迭代计算在内存中进行

* spark的DAG可以实现良好容错性（RDD不可变）

### Flink

#### 容错

* checkpoint机制

  负责定时制作分布式快照、对程序中的state进行备份

* state机制

  负责存储计算过程中的中间状态。备份落盘。

#### 分布式快照机制

##### 原理

将Chandy-Lamport算法改成适用于flink的算法，简单来说，持续创建分布式数据流及其算子状态的一致性快照。

这些快照充当一致性checkpoint，系统可以在发生故障时回滚。

##### 核心思想

在input source端插入barrier，控制barrier的同步来实现快照备份和exactly-once语义。一个算子要收到其上游所有算子的barrier后，才会记录状态，然后才会向下游发送它barris。

##### 实现

1. barriers在数据流源处被注入并行数据流中。第n次快照的barriers被插入的位置是快照所包含数据在数据源中最大位置，如分区中最后一条记录的偏移量，将该位置报告给checkpoint协调器（JobManager）。
2. 然后barriers向下流动，当一个中间操作算子从其所有输入流中收到第n次快照的barriers时，它会为快照n发出barriers进入其所有输出流中。一旦sink操作算子从其所有输入流接收到快照n的barriers，它就向checkpoint协调器确认快照n完成。所有sink确认快照后，意味着第n次快照已完成。
3. 一旦完成快照n，job将永远不再向数据源请求n次快照之前的数据

#### Exactly-once语义

对于一条message,receiver确保只收到一次

Flink实现Exactly once的策略: Flink会持续地对整个系统做snapshot,然后把global state(根据config文件设定)储存到master node或HDFS.当系统出现failure,Flink会停止数据处理,然后把系统恢复到最近的一次checkpoint.

##### 实现

通过**两阶段提交**和**状态保存**来实现端到端一致性语义

* 开始事务：对每个checkpoint，创建一个事务，事务对应一个临时文件夹，将数据写入此文件夹中
* 预提交：将内存中缓存的数据写入临时文件中
* 正式提交：将之前写完的临时文件放入目标目录下（这代表最终的数据会有一些延迟）
* 丢弃：丢弃临时文件

从kafka与flink角度

* 第一条数据来了后，开启一个kafka事务，正常写入kafka分区日志但标记为未提交，这就是“预提交”
* jobmanager触发checkpoint操作，barrier从source开始向下传递，遇到barrier的算子将状态存入状态后端，并通知jobmanager
* sink连接器接收到barrier，保存当前状态，存入checkpoint，通知JM，并开启下一阶段的事务，用于提交下个checkpoint的数据
* JM收到所有任务的通知，发出确认信息，表示checkpoint完成
* sink任务收到JM的确认信息，正式提交这段时间的数据
* 外部kafka关闭事务，提交的数据可以正常消费了

若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。

#### 三层Graph

* StreamGraph

  调用流处理api直接生成的图

  client上生成

* JobGraph

  合并

  client上生成

* ExecutionGraph

  根据并行度把每一个任务拆开，数据从哪个子任务来、发送给哪个子任务

  JM上生成

* 物理执行图

  task上执行

#### 任务调度（执行流程）

原始代码 ->客户端解析成 logical graph（StreamGraph+JobGraph） -> 客户端（UI、命令行）发送给JM

* 客户端对graph进行调整，可以合并的操作进行合并，graph合并后得到新的graph: job graph

* 客户端将graph和jar包等提交给JM

* JM进行分析，判断当前并行度，每个任务有几个并行子任务，需要多少slot，分配

* JM向RM申请资源，RM向TM提出slot资源注册请求（TM将自己可用的资源注册在RM上）

  TM的slots资源可以不完全用完，这与当前并行度（所需slots）有关

* JM一旦它获取到了足够的资源，就会将ExecutionGraph分发到真正运行它们的TM上。

* 而在运行过程中，JM会负责所有需要中央协调的操作，比如说TM的分发、停止、取消，以及checkpoints指令。

#### watermark

处理乱序数据

##### 取值

取当前所有已经到达数据的时间戳的最大值再减去一个固定的值，固定值是乱序程度最大值

#### 算子链

指JobGraph为什么要合并某些算子

##### 优势

多线程切换开销太大的话会影响到吞吐量，那么将多个算子合并成一个算子，用一个线程去处理。

注意每一个TM都是一个jvm进程，里面进行的每一个任务即是一个独立的线程，线程所占据的资源即是slot

##### 进一步优化

flink允许不同task共享slot，前提是同一个job内部，结果就是每个slot都可以执行job的一整个pipeline

##### 好处

1.Flink 集群所需的taskslots数与job中最高的并行度一致。也就是说我们不需要再去计算一个程序总共会起多少个task了。

2.更容易获得更充分的资源利用。如果没有slot共享，那么非密集型操作source/flatmap就会占用同密集型操作 keyAggregation/sink 一样多的资源。如果有slot共享，将基线的2个并行度增加到6个，能充分利用slot资源，同时保证每个TaskManager能平均分配到重的subtasks，比如keyby/window/apply操作就会均分到申请的所有slot里，这样slot的负载就均衡了。

#### 与Spark Streaming区别

* 运行模型

  事件驱动：事件驱动的app是一种状态应用app，它会从一个或多个流中注入事件，通过触发计算更新状态，或外部动作对注入的事件做出反应。

  微批处理：批量处理，ss每个批次都是一个spark core任务。

* 读取数据源 与kafka

  消费 kafka 的数据调用 poll 的时候是批量获取数据的(可以设置批处理大小和超时时间)，这就不能叫做事件触发了。而实际上，flink 内部对 poll 出来的数据进行了整理，然后逐条 emit，形成了事件触发的机制。调用 env.execute 相比于 Spark Streaming 少了设置批处理时间，还有一个显著的区别是 flink 的所有算子都是 lazy 形式的，调用 env.execute 会构建 jobgraph。client 端负责 Jobgraph 生成并提交它到集群运行；而 Spark Streaming的操作算子分 action 和 transform，其中仅有 transform 是 lazy 形式

* 任务调度

  对于 flink 的流任务客户端首先会生成 StreamGraph，接着生成 JobGraph，然后将 jobGraph 提交给 Jobmanager 由它完成 jobGraph 到 ExecutionGraph 的转变，最后由 jobManager 调度执行。

  可以看出 flink 的拓扑生成提交执行之后，除非故障，否则拓扑部件执行位置不变，并行度由每一个算子并行度决定，类似于 storm。而 spark Streaming 是每个批次都会根据数据本地性和资源情况进行调度，无固定的执行拓扑结构。 flink 是数据在拓扑结构里流动执行，而 Spark Streaming 则是对数据缓存批次并行处理。

* 时间语义

* Exactly-once

  对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰一次处理语义。

#### 增量迭代

#### 时间

1.12修改默认时间类型为event time

processing time 然而在分布式和异步环境中，处理时间不能提供消息事件的时序性保证，因为它受到消息传输延迟，消息在算子之间流动的速度等方面制约。ss只提供处理时间。

event time 基于事件时间进行处理的流程序可以保证事件在处理的时候的顺序性，但是基于事件时间的应用程序必须要结合 watermark 机制。基于事件时间的处理往往有一定的滞后性，因为它需要等待后续事件和处理无序事件，对于时间敏感的应用使用的时候要慎重考虑。

integer time 事件在 source 算子处获取 source 的当前时间作为事件注入时间，后续的基于时间的处理算子会使用该时间处理数据。

流批一体情况下：

* 流处理中，二者是松散关系，处理时间略微落后于事件时间，对流作1个小时的聚合，处理时间可以看作是事件时间的近似
* 但假如是批处理，处理时间与事件时间就没有多大区别，因为处理的很有可能是多天之前积累下来的数据

### Kubernetes

Kubernetes是用于自动部署，扩展和管理容器化应用程序的开源系统。它将组成应用程序的容器组合成逻辑单元，以便于管理和服务发现。

#### 特性

1. **服务发现与负载均衡**：无需修改你的应用程序即可使用陌生的服务发现机制。
2. 存储编排：自动挂载所选存储系统，包括本地存储。
3. Secret和配置管理：部署更新Secrets和应用程序的配置时不必重新构建容器镜像，且不必将软件堆栈配置中的秘密信息暴露出来。
4. 批量执行：除了服务之外，Kubernetes还可以管理你的批处理和CI工作负载，在期望时替换掉失效的容器。
5. **水平扩缩**：使用一个简单的命令、一个UI或基于CPU使用情况自动对应用程序进行扩缩。
6. 自动化上线和回滚：Kubernetes会分步骤地将针对应用或其配置的更改上线，同时监视应用程序运行状况**以确保你不会同时终止所有实例**。
7. 自动装箱：根据资源需求和其他约束自动放置容器，同时避免影响可用性。
8. **自我修复**：重新启动失败的容器，在节点死亡时替换并重新调度容器，杀死不响应用户定义的健康检查的容器。

#### 结构

* Master：管理整个集群，协调所有活动（调度、维护、扩容、更新）

* Node：托管正在运行的应用，可以是一个虚拟机或物理机，充当工作机器角色

* Deployment：负责创建和更新应用程序的实例

* Pod：逻辑主机，负责托管应用实例，包括多个应用程序容器及这些容器的共享资源（存储、网络、运行信息）

  一个Node有多个Pod，一个Pod有多个容器

* Service：抽象层，定义了一组Pod的逻辑集合（因此可以跨Node组成一个Service），为这些pod支持外部流暴露、负载均衡和服务发现

  尽管每个Pod 都有一个唯一的IP地址，但是如果没有Service，这些IP不会暴露在群集外部。Service允许您的应用程序接收流量。

<img src="/k8s-service.webp" style="zoom:50%;" />

#### 项目为什么用k8s

#### 组件

* Master组件

  对集群进行全局决策，检测和响应集群时间（如副本数减少时自动创建新pod）

  * kube-apiserver：master节点上提供k8s api服务的组件

  * etcd：保存了k8s集群的一些数据，如pod的副本数，pod的期望状态与现在状态

  * scheduler：master节点上的调度器，负责选择节点让pod在节点上运行

    kube-scheduler 给一个 pod 做调度选择包含两个步骤：
     1、过滤
     2、打分

    过滤阶段会将所有满足 Pod 调度需求的 Node 选出来。例如，PodFitsResources 过滤函数会检查候选 Node 的可用资源能否满足 Pod 的资源请求。在过滤之后，得出一个 Node 列表，里面包含了所有可调度节点；通常情况下，这个 Node 列表包含不止一个 Node。如果这个列表是空的，代表这个 Pod 不可调度。

    在打分阶段，调度器会为 Pod 从所有可调度节点中选取一个最合适的 Node。根据当前启用的打分规则，调度器会给每一个可调度节点进行打分。

    最后，kube-scheduler 会将 Pod 调度到得分最高的 Node 上。如果存在多个得分最高的 Node，kube-scheduler 会从中随机选取一个。

  * controller：master节点的控制器，在节点出现故障时进行通知和响应，对节点的pod状态进行监控

* Node组件

  * kubelet：管理Node而且是Node与Master通信的代理，保证容器都运行在pod中

    唯一标识一个node节点

  * kube-proxy：一个代理，通过代理创建一个虚拟ip，**通过这个ip与pod进行交流**

  * container runtime：容器运行环境，负责在节点上运行容器的软件

* 附加组件

  * DNS：对k8s集群进行域名解析
  * Dashboard
  * 集群层面日志：负责将容器的日志数据保存到一个集中的日志存储中，该存储能提供搜索和浏览接口
  * 容器资源监控：将关于容器的常见时间序列度量值保存到一个集中的数据库中，提供界面

#### k8s流程

1. 准备好yaml，通过kubectl发送到api server中
2. api server接收到客户端的请求，将请求内容保存到etcd中
3. scheduler监测etcd，发现没有分配节点的pod对象，通过过滤和打分筛选出最适合的节点运行pod
4. 节点通过container runtime运行对应pod的容器以及创建对应的副本数
5. 节点上的kubelet会对自己节点上的容器进行管理
6. controler会监测集群中的每个节点，发现期望状态和实际状态不符合的话，通知对应的节点
7. 节点收到通知，通过container runtime来对pod内的容器进行收缩和扩张

对于容器来说，管理的单位是容器
对于k8s来说，管理的是一个pod应用
一个pod上可以运行多个容器，可以将pod理解为一个虚拟机，一个虚拟机上运行了多个容器

#### 通信

#### 弹性伸缩机制

在 Kubernetes 的生态中，在多个维度、多个层次提供了不同的组件来满足不同的伸缩场景。

有三种弹性伸缩

- CA（Cluster Autoscaler）：Node级别自动扩/缩容cluster-autoscaler组件
- HPA（Horizontal Pod Autoscaler）：Pod个数自动扩/缩容
- VPA（Vertical Pod Autoscaler）：主要使用场景是有状态应用

##### CPA

扩容：Cluster AutoScaler定期检测是否有充足的资源来调度新创建的pod，当资源不足时会调用Cloud Provider创建新的Node

缩容：Cluster AuthScaler也会定期检测Node的资源使用情况，当一个Node长时间资源利用率都很低时自动将其所在虚拟机从云服务商中删除。此时，原来的Pod会自动调度到其他Node上面。

##### HPA

**定义**

根据资源利用率或者自定义指标自动调整replication controller, replica set或deployment，实现部署的自动扩展和缩减。

操作对象是Replication Controller、ReplicaSet或者Deployment对应的Pod（k8s中可以控制Pod的是rc、rs、deployment），根据观察到的**CPU使用量与用户的阈值**进行比对，做出是否需要增加或者减少**实例数量**的决策。controller目前使用heapSter来检测CPU使用量，检测周期默认是30秒。

**工作原理**

Metrics Server 持续采集所有 Pod 副本的指标数据(CPU使用率)。HPA 控制器通过 Metrics Server 的 API获取这些数据，基于用户定义的扩缩容规则进行计算，得到目标 Pod **副本数量**。当目标 Pod 副本数量与当前副本数量不同时，HPA 控制器就向 **Pod 的副本控制器（Deployment、RC 或 ReplicaSet）**发起 scale 操作，调整 Pod 的副本数量，完成扩缩容操作 

**冷却周期**

为了保证集群的稳定性。由于评估的度量标准是动态特性，副本的数量可能会不断波动。有时被称为颠簸， 所以在每次做出扩容缩容后，冷却时间是多少。在 HPA 中，默认的扩容冷却周期是 3 分钟，缩容冷却周期是 5 分钟。

#### Deployment

负责创建与更新应用程序的实例，位于Master中。创建Deployment后，Kubernetes Master 将**应用程序**实例**调度**到集群中的各个**节点**上。如果托管实例的**节点**关闭或被删除，Deployment控制器会将该实例替换为群集中**另一个节点**上的实例。这提供了一种自我修复机制来解决机器故障维护问题。

可以使用Kubernetes命令行界面Kubectl创建和管理Deployment。Kubectl使用Kubernetes API与集群进行交互。

#### exec

#### 如何支持有状态应用

#### 集群奔溃

先停止k8s相关组件运行，并在etcd中手动删除对应对象，最后再重新启动k8s

### Docker

docker容器实际上就是运行的一个进程，只不过由于docker帮助我们包装了这个进程，给这个进程加以一个可运行的微linux环境而已，让我们感觉看起来"像"虚拟机而已。所以也就不奇怪，为什么容器的启动是秒级的，启动一个虚拟机是分钟级别的。

#### 与虚拟机区别

docker提供的是linux内核中最核心的服务，基于namespace提供基本隔离，基于cgroup提供资源隔离，启动开销是秒级

docker虚拟内存地址 -> 宿主机物理内存地址

虚拟机额外有个hypervision进行对物理宿主机的整个抽象，启动开销是分钟级，因为要先启动一个完整的虚拟操作系统

vm虚拟内存地址 -> 抽象物理内存地址 -> 宿主机物理内存地址

#### cgroup

cgroup是linux内核实现、用于控制linux系统资源的组件。

控制组，它提供了一套机制用于控制一组特定进程对资源的使用。cgroup绑定一个进程集合到一个或多个子系统上。

### Structed Streaming

也是微批模式，与Spark SQL结合更紧密，增加了增量处理功能（增量就是为了状态和流表功能的实现）

支持watermark

支持事件时间，处理时间