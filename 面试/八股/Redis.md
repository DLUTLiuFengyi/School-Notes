### Redis

Redis集群：主从架构，读写分离，以实现高并发。

选择master用Raft，哨兵同步数据用Gossip。

#### 数据结构

* String

  常用于需要计数的场景（用户访问次数、热点文章的点赞转发数量）

* list 链表 是一个双向链表，支持反向遍历

  发布与订阅，消息队列，慢查询 ，能存储2^32-1个数

* hash 类似于HashMap，内部实现也是数组+链表，是一个string类型的field和value的映射表，**特别适用于存储对象**，后续操作只需修改该对象中某个字段的值

  存储用户信息，商品信息，系统中对象数据的存储

* set 类似于HashSet，有判断某元素是否存在其中的接口，轻易实现交并差集操作

  将用户所的关注人存在一个集合中，将所有粉丝存在一个集合，用其进行共同关注、共同好友、共同喜好等交集操作

* sorted set 增加一个权重参数，使集合中元素有序排序，类似HashMap+TreeSet

  直播系统，实时排行信息

* bitmap 存储连续的二进制数字，通过bitmap只需一个bit位来表示某个元素对应的值或状态，key就是元素本身

  需要保存状态信息（是否签到、是否登录）并需要对这些信息进行分析的场景，如用户签到、活跃情况（某日是否登录）、用户行为统计（是否点赞过某个视频）、是否在线等

list能做的sorted set都能做，但list占用的空间比sorted set小很多

#### 单线程模型

Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器（单线程方式执行）使用 I/O 多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

通过 **IO多路复用** 来监听来自客户端的大量连接（监听多个socket）。其会将感兴趣的事件及类型（读写）注册到内核中并监听每个事件是否发生。

**好处**：让redis不需额外创建多余的线程来监听大量连接，降低了资源消耗

此外，redis服务器是一个事件驱动程序，需要处理文件事件和时间事件

##### 文件事件处理器

1. 多个socket
2. IO多路复用程序
3. 文件事件分派器（将socket关联到相应的事件处理器）
4. 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

##### 为什么用单线程

1. 更好的可维护性，方便开发

2. 单线程也能并发处理请求

3. redis绝大部分操作的性能瓶颈都不是cpu（决定性因素），主要是内存和网络

   redis不是cpu密集型服务，如果不启动AOF备份，所有redis操作都会在内存中完成，不会涉及任何IO，数据读写只发生在内存，所以速度非常快

多线程的线程切换也会带来额外开销（保存线程1上下文，加载线程2上下文）

#### 内存淘汰机制

“MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据”

6种方案

1. 最近最少使用：从已设置过期时间的数据集`server.db[i].expires`中挑选最近最少使用的数据淘汰
2. 从已设置过期的数据集中挑选将要过期的数据淘汰
3. 从已设置过期的数据集中任意选择数据淘汰
4. 内存不足以写入新数据时，在key空间中，移除**最近最少**使用的key（最常用）
5. 从数据集`server.db[i].dict`中任意选择数据淘汰
6. 内存不足以写入新数据时，写新数据会直接报错
7. 4.0版本更新：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰
8. 4.0版本更新：内存不足时，在key空间中，移除**最不经常**使用的key

#### 持久化

redis持久化通过RDB和AOF实现。4.0版本支持RDB和AOF混合持久化，AOF重写时直接把RDB内容写到AOF文件开头，好处是结合二者优点，快速加载同时避免丢失数据，缺点是AOF里的RDB部分是压缩格式不是AOF格式，可读性差。

##### RDB文件（快照）

通过保持DB中的键值对来记录DB状态。创建快照来得到某个时间点的内存数据的副本，然后将快照复制到其他服务器。

把数据以快照形式保存在磁盘上。指定时间间隔内将内存中数据集快照写入磁盘。

RDB是二进制格式文件，因此存储到磁盘与恢复数据都很快。对于不同数据类型，只需看读取多少字节、怎样去读。只需按照RDB文件格式的协议去解读文件，就能准确解读成字符。

RDB快照是一次全量备份，耗时

##### AOF append only file

会在每次收到来自客户端的写请求时，将其记录到日志中，每次 Redis 服务器启动时都会重放 AOF 日志构建原始的数据集，保证数据的持久性。

实时性更好。通过保存redis执行的写命令来记录DB状态（保存所有修改DB的写命令）

命令请求先保存到AOF缓冲区，之后定期写入并同步到AOF文件

服务器只需载入并重新执行保存在AOF文件中的命令，就可以还原DB本来的状态

对同一份数据，AOF日志文件比RDB数据快照文件大。AOF开启后写的QPS比RDB支持的低

#### 布隆过滤器

应对缓存穿透问题（大量不存在于缓存的key访问）。先用布隆判断。布隆说某元素存在，小概率不存在，说某元素不存在，则一定不存在。

##### 一个元素加入过滤器流程

1. 使用bl中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数就有几个哈希值）
2. 根据得到的哈希值，在位数组中将对应下标值设为1

##### 判断流程

1. 对给定元素再次进行相同哈希计算
2. 得到值之和判断位数组中每个元素是否都为1，如果都为1，说明这个值在bl中，如果存在一个值不为1，则不在bl中

一个问题是，不同字符串可能hash出来的位置相同，此时需要适当增加位数组大小或调整hash函数

#### 哨兵

##### 主从切换

主从切换是由哨兵机制执行的，一定有超过预设数量quorum的哨兵实例和主库的心跳都超时了，才会将其判断为客观下线，然后哨兵执行切换操作。切换完成后，客户端会和新主库进行通信，发送请求。

#### Raft

#### 脑裂

##### 可能起因

原主节点并没有真正故障，在主从切换过程中客户端仍然与原主库通信

##### 为何有数据丢失

主从切换后，在哨兵安排下， 原主节点在全量同步新主节点的最后阶段，需要清空本地数据

##### 解决方法

让原主节点无法接收客户端请求

```txt
min-slaves-to-write：主库能进行数据同步的最少从库数量； 

min-slaves-max-lag：主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟
```

### 3种缓存读写策略

热点数据可以提前放入cache中

#### cache aside pattern 旁路缓存

适合读请求较多

服务端同时维护DB和cache，以DB结果为准

写：先更新DB，然后直接删除cache

读：从cache中读数据，读到就直接返回；读不到，从DB中读然后返回；服务器再把从DB获取到的数据放到cache中

##### 为什么不能先删除cache再更新DB？

因为为造成DB和cache数据不一致，比如请求1先写A，请求2随后读A的话会产生数据不一致（请求1先把cache中A删除，请求2从DB中读数据，请求1才把DB中的A更新成自己想更新的值）

那原来的先更新DB后删除cache的方法就没问题吗？

理论上还是会有不一致问题，但概率很小，因为cache写入的速度比DB写入的数据快很多

##### 缺点

* 首次请求数据一定不在cache

  解决：可先把热点数据提前放进cache

* 写较频繁的话cache中的数据会频繁被删除，会影响命中率

  解决1：强一致性场景的话，更新DB同时更新cache，加一个锁保证更新cache时线程安全

  解决2：短暂允许不一致场景的话，更新DB同时更新cache，但给cache加一个较短时间间隔，可保证即使数据不一致影响也较小

#### read/write through 读写穿透

服务端把cache视为主要数据存储，从中读取数据并将数据写入其中

cache负责将此数据读取和写入DB，减轻app(server?)职责

少用，因为cache写入DB功能少

写：先查cache，cache不在，直接更新DB；cache中存在，先更新cache，然后cache自己更新DB（同步更新）

读：从cache中读数据，读到就直接返回；读不到，cache自己从DB加载数据，然后返回

#### write behind pattern 异步缓存写入

也是由cache自己负责cache和DB的读写

Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新cache，不直接更新 DB，而是改为**异步批量**的方式来更新 DB。

消息队列中消息异步写入磁盘，InnoDB buffer pool机制

使用数据经常变化且对一致性要求不高，如浏览量、点赞量

### Redis实现分布式锁

双十一秒杀、优惠券

```txt
SENTEX key value
```

只有key不存在时，才把key的值设为value

若key已经存在，则不做任何操作

如果在释放锁时失败呢？把释放锁操作放进finally中

如果在中间执行业务代码的时候宕机呢？在获取锁的时候设置一个失效时间

假如在获取锁的时候就宕机呢？获取锁的`ops.ForValue().setIfAbsent(,,TimeUnit.SECONDS)`就能设置失效时间参数

锁要求形成**闭环**的形状（一个线程上锁了，要等线程业务执行完，锁才释放）？可以每个线程都绑定一个uuid，把SENTEX的value设置成uuid，在释放锁的时候判断这个线程获取到的锁（key）对应的value与本线程的uuid是否相等

如何避免生成相同的uuid？ThreadLocal，把uuid放入threadlocal中，新来的线程的threadlocal中没有uuid，就生成uuid，放入threadlocal 

可重入性呢？（多次进入threadlocal判断是否有uuid的话，就会有问题）用计数器

锁失效问题？每隔一段时间重新设置失效时间

分布式锁：

* 互斥

* 超时（重点）

* 可重入（重点）

* 高可用

* 阻塞 非阻塞

  剩下拿不到锁的线程，不会直接返回

Redisson（真正的分布式锁框架）

### 内存限制的海量数据量问题

1g文件，内存1m，返回频数最高的100个词

给定a b两个文件，各存放50亿各url，每各url各占64字节，内存4g，找出a b文件共同的url

同一思想：分治

分支典型例子：归并

#### 问题1

72g文件，每一行都是独立的字符串，一台机子只有16g可用内存，要求读取内容然后按行排序，将排序结果保存在另一个文件？

将72g分成6个12g文件，分别放内存中排序，得到6个有序的12g文件

16g内存，如何合并文件？

将内存分成2份，8g输入缓存区+8g输出缓存区

第一个文件取4g+第二个文件取4g 进入8g输入缓存区，再用归并方法一一比较，结果输出到8g输出缓存区中

而8g的输出缓存区会满，就把这些有序的结果放到外部如DB中（得到8g有序文件），然后继续读外面第一个文件和第二个文件的内容，第一个读完就加快读第二个，然后依次得到3个8g的有序文件，而这3个有序文件其实可以直接合成24g文件

最后得到3个24g的有序文件

然后同样将任意2个有序文件分布拆分到内存进行一一比较...

#### 问题2

提取日访问次数最多的ip

每个ip是32位，2^32 = 4g 

4g的文件，可用内存4m

分成1024个文件

取每个ip的hash值，然后 hash(ip) % 1024，只要ip相同，那就能进到同一个文件

对每个文件，根据key计算ip数量，value为数量

#### 问题3

10亿个整数找出重复次数最多的100个整数

与2类似，每个文件求出频数最多的100个数，最后合并

#### 问题5

100亿个数找出最大前k个数

解法：思路确定，必须分块处理，然后再合并

1. 对每一块，找出k个最大的数，然后再合并比较

   （为什么每块都是前k个数？因为在每一块中第k+1大的数不可能在所有数中是前k大的）

   （为什么不是最大1个数？因为A块最大的k个数中最小的可能比B块最大的k个数中最大的要大）

   有分布式环境的话，就分布式处理

2. 堆排序：先用起始k个数构建一个最小堆（klogk），堆顶即为这k个数中最小的数，然后遍历一遍剩余的元素，每读到一个数，与剩余的数作比较

   * 若该元素比堆顶元素小，直接丢弃

   * 若该元素比堆顶元素大，用该元素替换堆顶，然后调整结构保持最小堆性质

     最坏情况是每次都要调整堆结构，因此维护堆的时间复杂度是(N-k)*O(logk)

   最后这个堆的元素就是前k大的数，时间复杂度为O(Nlogk)

   适合单机情况

3. 快排分组的思想：

   * 递归对所有数据分成[a, b), b, (b, d]两个区间，(b, d]区间内的数都是大于[a, b)区间内的数
   * 对(b, d]重复步骤1的操作，直到最右边区间个数小于k个（注意[a, b)区间不用划分）
   * 返回上一个区间，并返回此区间的数字数目。接着方法依然是对上一个区间的左边进行划分，分为[a2, b2), b2, (b2, d2]两个区间，取(b2, d2]区间。如果个数不够，继续步骤3操作；如果个数超过k，就重复步骤1操作，直到最后右边只有k个数为止。

